{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**\n",
    "\n",
    "The presented code is not optimized, it serves an educational purpose. It is written for CPU, it uses only fully-connected networks and an extremely simplistic dataset. However, it contains all components that can help to understand how an autoregressive model (ARM) works, and it should be rather easy to extend it to more sophisticated models. This code could be run almost on any laptop/PC, and it takes a couple of minutes top to get the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we go wild and use a dataset that is simpler than MNIST! We use a scipy dataset called Digits. It consists of ~1500 images of size 8x8, and each pixel can take values in $\\{0, 1, \\ldots, 16\\}$.\n",
    "\n",
    "The goal of using this dataset is that everyone can run it on a laptop, without any gpu etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DigitsDataset --> \n",
      "\t dataset.shape: (1797, 64) \n",
      "\t index0.shape: (64,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at the Digits Dataset for intuition\n",
    "digitsDataset = load_digits().data\n",
    "print(f'DigitsDataset --> \\n\\t dataset.shape: {digitsDataset.shape} \\n\\t \\\n",
    "index0.shape: {digitsDataset[0].shape}')\n",
    "# Note that there are no labels but only image pixels present in our data\n",
    "\n",
    "# visualize some of the inputs\n",
    "num = 3\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "    \n",
    "for i in range(num):\n",
    "    rand_index = np.random.randint(0, digitsDataset.shape[0])\n",
    "    fig.add_subplot(1, num, i+1)\n",
    "    plt.imshow(digitsDataset[rand_index].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pytorch custom Dataset (\"Digits\"). \n",
    "# To do so: [Extend the \"Dataset\" Class, implement __len__() and __getitem__() functions]\n",
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARM code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the blogpost for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to be used in our Causal Conv1d implementations in the Autoregressive Model(ARM)\n",
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    A causal 1D convolution.\n",
    "    \"\"\"\n",
    "# Note: \"A\" means that the input at time t is not fed into(i.e. masked) the model (causal).\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, A=False, **kwargs):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "\n",
    "        # attributes:\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        self.A = A # flag that indicates whether current time step input will be fed into the model as input\n",
    "        \n",
    "        self.padding = (kernel_size - 1) * dilation + A * 1 \n",
    "        # Note that \"padding\" is required since for the first convolution operation given a sequence x, we will\n",
    "        # need to have F-1 many entries to multiply with the kernel to produce the output for the time step= 0.\n",
    "        # Since we do not have input values for the sequence at any time step earlier than t=0, we pad only the \n",
    "        # left side of the sequence x, so that the kernel can have enough inputs to convolve at time step t=0 \n",
    "        # to produce the output of the first(t=0) convolution operation. Also, note that no padding on the right\n",
    "        # is applied since kernel convolves to right starting form the left side. \n",
    "\n",
    "        # module:\n",
    "        self.conv1d = torch.nn.Conv1d(in_channels, out_channels,\n",
    "                                      kernel_size, stride=1,\n",
    "                                      padding=0,\n",
    "                                      dilation=dilation,\n",
    "                                      **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.pad(x, (self.padding, 0)) # Pad the left of the sequnce so that conv for t={0,...,F-1} can match size\n",
    "        conv1d_out = self.conv1d(x)\n",
    "        if self.A:\n",
    "            return conv1d_out[:, :, : -1] # for causality purposes ignore the most recent time step output\n",
    "        else:\n",
    "            return conv1d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1.e-5\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes) # Convert gt pixel values to one_hot for masking LL's\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS)) # Calculates Log Likelihood(LL) for the predicted pixel values\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARM(nn.Module):\n",
    "    def __init__(self, net, D=2, num_vals=256):\n",
    "        super(ARM, self).__init__()\n",
    "\n",
    "        print('ARM by JT.')\n",
    "\n",
    "        self.net = net\n",
    "        self.num_vals = num_vals # number of possible pixel values (i.e. output layer dimension)\n",
    "        self.D = D # Image Dimension (sqrt(D) by sqrt(D) image)\n",
    "\n",
    "    def f(self, x): # computes forward pass and returns softmax probs.\n",
    "        h = self.net(x.unsqueeze(1)) # Extend dimensions of the input for batch processing\n",
    "\n",
    "        h = h.permute(0, 2, 1) # final_shape = (1, len(x), num_vals)\n",
    "        p = torch.softmax(h, 2) # calculate pred probs of pixel values for each pixel location\n",
    "        return p\n",
    "        \n",
    "    def forward(self, x, reduction='avg'):\n",
    "        if reduction == 'avg':\n",
    "            return -(self.log_prob(x).mean()) # multiply by -1 to have Negative Log Likelihood (NLL)\n",
    "        elif reduction == 'sum':\n",
    "            return -(self.log_prob(x).sum())\n",
    "        else:\n",
    "            raise ValueError('reduction could be either `avg` or `sum`.')\n",
    "\n",
    "    def log_prob(self, x): # returns Log Likelihood (LL)\n",
    "        mu_d = self.f(x)\n",
    "        log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
    "        \n",
    "        return log_p\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        x_new = torch.zeros((batch_size, self.D))\n",
    "\n",
    "        for d in range(self.D): # sample new image pixel by pixel\n",
    "            p = self.f(x_new)\n",
    "            x_new_d = torch.multinomial(p[:, d, :], num_samples=1) # sample pixel value wrt softmax weights for every batch\n",
    "            x_new[:, d] = x_new_d[:,0]\n",
    "\n",
    "        return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions: training, evaluation, plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's rather self-explanatory, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model')\n",
    "\n",
    "    model_best.eval() # turn on the evaluation mode of the pytorch model\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=''):\n",
    "    x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + '.model')\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "    nll_val = [] # negative log likelihood loss history for validations\n",
    "    best_nll = 1000.\n",
    "    patience = 0 # keeps track of number of consecutive non improvements in the calculated loss(for early stopping)\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train() # put model into training mode (e.g. turns on layers such as dropout if present)\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            if hasattr(model, 'dequantization'):\n",
    "                if model.dequantization:\n",
    "                    batch = batch + torch.rand(batch.shape)\n",
    "            loss = model.forward(batch) # forward pass the input data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True) # compute gradients\n",
    "            optimizer.step() # apply parameter updates\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:# early stopping\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "result_dir = 'results/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'arm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64   # input dimension\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ARM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARM by JT.\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "    CausalConv1d-1        [1, 256, 64]           2,048           2,048\n",
      "       LeakyReLU-2        [1, 256, 64]               0               0\n",
      "    CausalConv1d-3        [1, 256, 64]         459,008         459,008\n",
      "       LeakyReLU-4        [1, 256, 64]               0               0\n",
      "    CausalConv1d-5        [1, 256, 64]         459,008         459,008\n",
      "       LeakyReLU-6        [1, 256, 64]               0               0\n",
      "    CausalConv1d-7         [1, 17, 64]          30,481          30,481\n",
      "=======================================================================\n",
      "Total params: 950,545\n",
      "Trainable params: 950,545\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "likelihood_type = 'categorical'\n",
    "\n",
    "num_vals = 17 # number of discrete values that each pixel can have\n",
    "\n",
    "kernel = 7 # Filter/Kernel size\n",
    "\n",
    "# Neural Network that will be used to learn a parameterized function of the probability distributaion of data\n",
    "net = nn.Sequential( \n",
    "    CausalConv1d(in_channels=1, out_channels=M, dilation=1, kernel_size=kernel, A=True, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=M, dilation=1, kernel_size=kernel, A=False, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=M, dilation=1, kernel_size=kernel, A=False, bias=True),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(in_channels=M, out_channels=num_vals, dilation=1, kernel_size=kernel, A=False, bias=True))\n",
    "\n",
    "model = ARM(net, D=D, num_vals=num_vals)\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(summary(model, torch.zeros(1, 64), show_input=False, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play! Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=118.40444893973215\n",
      "saved!\n",
      "Epoch: 1, val nll=112.05866001674107\n",
      "saved!\n",
      "Epoch: 2, val nll=109.60898088727679\n",
      "saved!\n",
      "Epoch: 3, val nll=107.97957868303571\n",
      "saved!\n",
      "Epoch: 4, val nll=105.75233258928571\n",
      "saved!\n",
      "Epoch: 5, val nll=103.51088936941964\n",
      "saved!\n",
      "Epoch: 6, val nll=101.12944196428572\n",
      "saved!\n",
      "Epoch: 7, val nll=98.84278738839286\n",
      "saved!\n",
      "Epoch: 8, val nll=97.16267926897322\n",
      "saved!\n",
      "Epoch: 9, val nll=95.62146135602678\n",
      "saved!\n",
      "Epoch: 10, val nll=95.0568017578125\n",
      "saved!\n",
      "Epoch: 11, val nll=93.85328404017856\n",
      "saved!\n",
      "Epoch: 12, val nll=93.33431919642857\n",
      "saved!\n",
      "Epoch: 13, val nll=93.42415597098214\n",
      "Epoch: 14, val nll=92.62612444196428\n",
      "saved!\n",
      "Epoch: 15, val nll=92.30178850446428\n",
      "saved!\n",
      "Epoch: 16, val nll=91.67514718191964\n",
      "saved!\n",
      "Epoch: 17, val nll=92.06510811941965\n",
      "Epoch: 18, val nll=91.40755022321429\n",
      "saved!\n",
      "Epoch: 19, val nll=91.23511300223214\n",
      "saved!\n",
      "Epoch: 20, val nll=91.21022321428572\n",
      "saved!\n",
      "Epoch: 21, val nll=90.66482979910714\n",
      "saved!\n",
      "Epoch: 22, val nll=90.50875\n",
      "saved!\n",
      "Epoch: 23, val nll=90.41828125\n",
      "saved!\n",
      "Epoch: 24, val nll=90.43954171316965\n",
      "Epoch: 25, val nll=90.48443429129465\n",
      "Epoch: 26, val nll=90.27427873883929\n",
      "saved!\n",
      "Epoch: 27, val nll=89.76610979352678\n",
      "saved!\n",
      "Epoch: 28, val nll=89.66515625\n",
      "saved!\n",
      "Epoch: 29, val nll=89.69711495535714\n",
      "Epoch: 30, val nll=89.71298200334822\n",
      "Epoch: 31, val nll=89.88051618303571\n",
      "Epoch: 32, val nll=89.56811872209822\n",
      "saved!\n",
      "Epoch: 33, val nll=89.37948869977679\n",
      "saved!\n",
      "Epoch: 34, val nll=89.17568917410715\n",
      "saved!\n",
      "Epoch: 35, val nll=89.57160226004464\n",
      "Epoch: 36, val nll=89.49403390066965\n",
      "Epoch: 37, val nll=89.49069754464286\n",
      "Epoch: 38, val nll=89.47925571986607\n",
      "Epoch: 39, val nll=89.79192661830358\n",
      "Epoch: 40, val nll=89.47836635044642\n",
      "Epoch: 41, val nll=88.97412248883928\n",
      "saved!\n",
      "Epoch: 42, val nll=89.53271763392857\n",
      "Epoch: 43, val nll=89.54116280691964\n",
      "Epoch: 44, val nll=89.27927176339286\n",
      "Epoch: 45, val nll=89.17479352678572\n",
      "Epoch: 46, val nll=89.17264299665179\n",
      "Epoch: 47, val nll=89.33429966517858\n",
      "Epoch: 48, val nll=89.61485979352679\n",
      "Epoch: 49, val nll=89.49227399553571\n",
      "Epoch: 50, val nll=89.56066336495536\n",
      "Epoch: 51, val nll=89.732392578125\n",
      "Epoch: 52, val nll=89.89892717633928\n",
      "Epoch: 53, val nll=89.6885546875\n",
      "Epoch: 54, val nll=89.79173967633929\n",
      "Epoch: 55, val nll=89.89410853794642\n",
      "Epoch: 56, val nll=90.20610491071429\n",
      "Epoch: 57, val nll=90.29151925223215\n",
      "Epoch: 58, val nll=89.55106724330358\n",
      "Epoch: 59, val nll=90.56727678571428\n",
      "Epoch: 60, val nll=90.03813546316964\n",
      "Epoch: 61, val nll=90.73088448660714\n",
      "Epoch: 62, val nll=90.29228934151786\n"
     ]
    }
   ],
   "source": [
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                       training_loader=training_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=86.46001337038591\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
